#!/usr/bin/env python3

"""Extract values from the Drupal 7 EBMS database for upgrade to Drupal 9.

This script pulls information from the EBMS Drupal 7 production
database and assembles collections of each of the different kinds of
corresponding records needed for the rewritten Drupal 9 implementation
of the EBMS. Each of these collected sets is serialized to a text
file, each line of which contains the JSON-encoding string for a
single record. This means that a JSON parser cannot process one of
these files as a unit, but must be fed each line separately. This
approach serves two purposes. First, it avoids having the JSON parser
run out of memory. In addition, this facilitates the task of
identifying changed or added records between two separate runs of this
script.

It is important that the "unversioned/exported" directory created by a
previous run of the script be moved to "unversioned/baseline" before
the script is run again, in order to make it possible for the script
find-deltas-from-baseline.py to identify new and changed records from
the previous run. The script has been carefully designed to produce
the same JSON string for each record which has not changed from one
run to another in the source database (even, for example, when those
records contain new primary keys for the target database generated by
this script; see the code below which loads IDs from the
packet_article_ids file if that file exists).

The directory uncommitted/ebms3db.json must exist, containing the
credentials required for connecting to the Drupal 7 database. Since
this information is sensitive, it is not committed to the version
control repository.

Command-line options are available for generating a subset of the
exported records, useful for debugging purposes. Run ./export.py
--help for the available options.

The script generally takes under half an hour.

"""

from argparse import ArgumentParser
from datetime import datetime
from json import dump, dumps, load, loads
from pathlib import Path
from subprocess import Popen, PIPE
from ebms_db import DBMS


class Exporter:
    """Manages the export logic, supporting partial exports."""

    OLD_FILES_LOCATION = "sites/ebms.nci.nih.gov/files"
    OLD_ABSOLUTE = f"https://ebms.nci.nih.gov/{OLD_FILES_LOCATION}"
    NEW_FILES_LOCATION = "sites/default/files"
    SETS = (
        "articles",
        "boards",
        "docs",
        "files",
        "groups",
        "imports",
        "journals",
        "meetings",
        "messages",
        "packets",
        "summaries",
        "states",
        "tags",
        "topics",
        "travel",
        "users",
        "vocabularies",
    )
    STATE_MACHINE_NAMES = dict(
        ReadyInitReview="ready_init_review",
        RejectJournalTitle="reject_journal_title",
        RejectInitReview="reject_init_review",
        PassedInitReview="passed_init_review",
        Published="published",
        RejectBMReview="reject_bm_review",
        PassedBMReview="passed_bm_review",
        RejectFullReview="reject_full_review",
        PassedFullReview="passed_full_review",
        FYI="fyi",
        FullEnd="full_end",
        NotForAgenda="not_for_agenda",
        AgendaNoPaprChg="agenda_no_paper_change",
        AgendaFutureChg="agenda_future_change",
        AgendaBoardDiscuss="agenda_board_discuss",
        AgendaWrkGrpDiscuss="agenda_work_group_discuss",
        OnAgenda="on_agenda",
        FinalBoardDecision="final_board_decision",
        OnHold="on_hold",
        FullReviewHold="full_review_hold",
    )
    ROLE_MAP = {
        9: "admin_assistant",
        3: "administrator",
        5: "board_manager",
        4: "board_member",
        6: "branch_manager",
        8: "medical_librarian",
        7: "site_manager",
        10: "travel_admin",
    }
    USER_DEFAULT_TABLES = dict(
        review_format="field_data_dft_cite_review_format",
        review_per_page="field_data_dft_cite_review_items_per_page",
        review_sort="field_data_dft_cite_review_sort_key",
        search_per_page="field_data_dft_cite_search_items_per_page",
        search_sort="field_data_dft_cite_search_sort_key",
        board="field_data_dft_editorial_board",
        packet_article_sort="field_data_dft_packet_article_sort_key",
    )
    USER_DEFAULT_MAP = {
        "ebms_id": "id",
        "pmid": "source_id",
        "author": "author",
        "Title": "title",
        "Author": "author",
        "journal": "journal_title",
        "core_journal": "core",
        "publication_date": "year",
        "Journal Title": "journal",
        "EBMS ID": "ebms-id",
        "PMID": "pmid",
        "Journal": "journal",
        "Core Journals": "core",
        "View All": "all",
        20: "25",
    }
    REVIEW_SORT_MAP = {
        "core_journal": "core",
        "ebms_id": "state.article",
        "publication_date": "article.year",
        "pmid": "article.source_id",
        "title": "article.title",
        "journal": "article.journal_title",
    }
    IMPORT_DISPOSITIONS = dict(
        notListed="not_listed",
        reviewReady="review_ready",
        topicAdded="topic_added",
    )
    HOTEL_REQUEST_FORM_NODE_ID = 1
    REIMBURSEMENT_REQUEST_FORM_NODE_ID = 2
    MESSAGE_TYPES = dict(
        activity_agenda_published="agenda published",
        activity_cancelled_event="meeting canceled",
        activity_changed_event="meeting changed",
        activity_event_type="meeting type changed",
        activity_new_articles="articles published",
        activity_new_event="meeting published",
        activity_new_packet="packet created",
        activity_new_summary="summary posted",
    )
    MESSAGE_FIELDS = {
        "ad_hoc_groups",
        "boards",
        "individuals",
        "subgroups",
    }
    MEETING_TYPES = dict(
        in_person="In Person",
        remote="Webex/Phone Conf.",
    )

    def run(self):
        """Top-level processing entry point."""

        start = datetime.now()
        path = Path("../unversioned/exported")
        if not path.exists():
            path.mkdir()
        self.cursor = DBMS().connect().cursor()
        sets = self.opts.include or self.SETS
        for function in sets:
            if function in self.SETS:
                if not self.opts.exclude or function not in self.opts.exclude:
                    getattr(self, function)()
            else:
                print(f"don't know what to do with {function}")
        elapsed = datetime.now() - start
        print(f"elapsed time: {elapsed}")

    @property
    def opts(self):
        """Command-line options."""

        if not hasattr(self, "_opts"):
            choices = sorted(self.SETS)
            parser = ArgumentParser()
            parser.add_argument("--tier", default="PROD")
            parser.add_argument("--include", nargs="*", choices=choices)
            parser.add_argument("--exclude", nargs="*", choices=choices)
            parser.add_argument("--verbose", "-v", action="store_true")
            self._opts = parser.parse_args()
        return self._opts

    @property
    def cycles(self):
        """Map of integer row IDs to date strings."""

        if not hasattr(self, "_cycles"):
            self._cycles = {}
            self.cursor.execute("SELECT cycle_id, start_date FROM ebms_cycle")
            for row in self.cursor.fetchall():
                self._cycles[row["cycle_id"]] = str(row["start_date"])[:10]
        return self._cycles

    def articles(self):
        """Export separate JSON lines for each of the EBMS articles."""

        self.__article_relationships()
        topics = self.__article_topics()
        self.__announce("articles")
        if self.opts.verbose:
            collected = 0
        tags = {}
        self.cursor.execute("SELECT * FROM ebms_article_tag"
                            " WHERE topic_id IS NULL ORDER BY article_tag_id")
        for row in self.cursor.fetchall():
            article_id = row["article_id"]
            if article_id not in tags:
                tags[article_id] = []
            tags[article_id].append(row["article_tag_id"])
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} article tags")
            collected = 0
        internal_tags = {}
        self.cursor.execute("SELECT * FROM ebms_internal_article_tag "
                            "ORDER BY tag_pk")
        for row in self.cursor.fetchall():
            article_id = row["article_id"]
            if article_id not in internal_tags:
                internal_tags[article_id] = []
            internal_tags[article_id].append(dict(
                tag=row["tag_id"],
                added=str(row["tag_added"]),
            ))
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} internal tags")
            collected = 0
        internal_cmts = {}
        self.cursor.execute("SELECT * FROM ebms_internal_article_comment "
                            "ORDER BY comment_id")
        for row in self.cursor.fetchall():
            comment = row["comment_text"].strip()
            if comment:
                article_id = row["article_id"]
                if article_id not in internal_cmts:
                    internal_cmts[article_id] = []
                internal_cmts[article_id].append(dict(
                    user=row["user_id"],
                    entered=str(row["comment_date"]),
                    body=comment,
                ))
                if self.opts.verbose:
                    collected += 1
        if self.opts.verbose:
            print(f"collected {collected} internal comments")
            collected = 0
        legacy_ids = {}
        self.cursor.execute("SELECT * FROM ebms_legacy_article_id "
                            "ORDER BY legacy_id")
        for row in self.cursor.fetchall():
            legacy_ids[row["article_id"]] = row["legacy_id"]
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} legacy IDs")
            collected = 0
        full_text = {}
        self.cursor.execute("SELECT * FROM ebms_ft_unavailable")
        for row in self.cursor.fetchall():
            full_text[row["article_id"]] = dict(
                unavailable=True,
                flagged_as_unavailable=str(row["flagged"]),
                flagged_by=row["flagged_by"],
                notes=row["comment"],
            )
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} full-text unavailability records")
        if self.opts.verbose:
            self.cursor.execute("SELECT COUNT(*) AS total FROM ebms_article")
            total = self.cursor.fetchone()["total"]
            done = 0
        offset = 0
        batch_size = 10000
        path = "../unversioned/exported/articles.json"
        with open(path, "w", encoding="utf-8") as fp:
            while True:
                self.cursor.execute(
                    "SELECT article_id, imported_by, import_date, update_date,"
                    " data_mod, data_checked, full_text_id FROM ebms_article "
                    f"ORDER BY article_id LIMIT {offset}, {batch_size}"
                )
                offset += batch_size
                rows = self.cursor.fetchall()
                if not rows:
                    break
                for row in rows:
                    article_id = row["article_id"]
                    article = dict(
                        id=article_id,
                        imported_by=row["imported_by"],
                        import_date=str(row["import_date"]),
                    )
                    if article_id in topics:
                        article["topics"] = topics[article_id]
                    if article_id in tags:
                        article["tags"] = tags[article_id]
                    if article_id in internal_tags:
                        article["internal_tags"] = internal_tags[article_id]
                    if article_id in internal_cmts:
                        article["internal_comments"] = internal_cmts[article_id]
                    if article_id in legacy_ids:
                        article["legacy_id"] = legacy_ids[article_id]
                    if row["update_date"]:
                        article["update_date"] = str(row["update_date"])
                    if row["data_mod"]:
                        article["data_mod"] = str(row["data_mod"])[:10]
                    if row["data_checked"]:
                        article["data_checked"] = str(row["data_checked"])[:10]
                    if article_id in full_text:
                        article["full_text"] = full_text[article_id]
                    elif row["full_text_id"]:
                        article["full_text"] = dict(file=row["full_text_id"])
                    fp.write(f"{dumps(article)}\n")
                    if self.opts.verbose:
                        done += 1
                        print(f"\rexported {done} of {total} articles", end="")
            if self.opts.verbose:
                print()

    def boards(self):
        """Export a separate JSON line for each PDQ Board entity."""

        self.__announce("boards")
        self.cursor.execute("SELECT * FROM ebms_board ORDER BY board_id")
        path = "../unversioned/exported/boards.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                board = dict(
                    id=row["board_id"],
                    name=row["board_name"],
                    manager=row["board_manager"],
                    loe_guidelines=row["loe_guidelines"],
                    auto_imports=row["auto_imports"],
                    active=True,
                )
                fp.write(f"{dumps(board)}\n")

    def docs(self):
        """Export a separate JSON line for each of the EBMS documents."""

        self.__announce("docs")
        boards = {}
        self.cursor.execute("SELECT * FROM ebms_doc_board ORDER BY board_id")
        for row in self.cursor.fetchall():
            doc_id = row["doc_id"]
            if doc_id not in boards:
                boards[doc_id] = []
            boards[doc_id].append(row["board_id"])
        tags = {}
        self.cursor.execute("SELECT * FROM ebms_doc_tag ORDER BY tag_id")
        for row in self.cursor.fetchall():
            doc_id = row["doc_id"]
            if doc_id not in tags:
                tags[doc_id] = []
            tags[doc_id].append(row["tag_id"])
        topics = {}
        self.cursor.execute("SELECT * FROM ebms_doc_topic "
                            "ORDER BY topic_id")
        for row in self.cursor.fetchall():
            doc_id = row["doc_id"]
            if doc_id not in topics:
                topics[doc_id] = []
            topics[doc_id].append(row["topic_id"])
        self.cursor.execute("SELECT * FROM ebms_doc ORDER BY doc_id")
        path = "../unversioned/exported/docs.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                doc_id = row["doc_id"]
                doc = dict(
                    id=doc_id,
                    file=row["file_id"],
                    posted=str(row["when_posted"]),
                    description=row["description"],
                    dropped=row["drop_flag"],
                    tags=tags.get(doc_id),
                    boards=boards.get(doc_id),
                    topics=topics.get(doc_id),
                )
                fp.write(f"{dumps(doc)}\n")

    def files(self):
        """Export a separate JSON line for each public file in the system."""

        self.__announce("files")
        self.cursor.execute("SELECT * FROM file_managed ORDER BY fid")
        path = "../unversioned/exported/files.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                if row["uri"]:
                    values = dict(
                        fid=row["fid"],
                        uid=row["uid"],
                        filename=row["filename"],
                        uri=row["uri"],
                        filemime=row["filemime"],
                        filesize=row["filesize"],
                        created=row["timestamp"],
                        status=row["status"],
                    )
                    fp.write(f"{dumps(values)}\n")

    def groups(self):
        """Export JSON for the subgroups and ad-hoc groups."""

        self.__announce("groups")
        ad_hoc_group_boards = {}
        self.cursor.execute("SELECT * FROM ebms_ad_hoc_group_board "
                            "ORDER BY board_id")
        for row in self.cursor.fetchall():
            group_id = row["group_id"]
            if group_id not in ad_hoc_group_boards:
                ad_hoc_group_boards[group_id] = []
            ad_hoc_group_boards[group_id].append(row["board_id"])
        self.cursor.execute("SELECT * FROM ebms_ad_hoc_group "
                            "ORDER BY group_id")
        path = "../unversioned/exported/ad_hoc_groups.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                group_id = row["group_id"]
                group = dict(
                    id=group_id,
                    name=row["group_name"],
                )
                if group_id in ad_hoc_group_boards:
                    group["boards"] = ad_hoc_group_boards[group_id]
                fp.write(f"{dumps(group)}\n")
        self.cursor.execute("SELECT * FROM ebms_subgroup ORDER BY sg_id")
        path = "../unversioned/exported/subgroups.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                group = dict(
                    id=row["sg_id"],
                    name=row["sg_name"],
                    boards=[row["board_id"]]
                )
                fp.write(f"{dumps(group)}\n")

    def imports(self):
        """Export JSON for the import requests and jobs."""

        self.__announce("import jobs")
        dispositions = {}
        self.cursor.execute("SELECT disposition_id, text_id "
                            "FROM ebms_import_disposition")
        for row in self.cursor.fetchall():
            dispositions[row["disposition_id"]] = row["text_id"]
        actions = {}
        offset = 0
        batch_size = 10000
        while True:
            self.cursor.execute("SELECT * from ebms_import_action ORDER BY "
                                f"action_id LIMIT {offset}, {batch_size}")
            offset += batch_size
            rows = self.cursor.fetchall()
            if not rows:
                break
            for row in rows:
                text_id = dispositions[row["disposition_id"]]
                action = dict(
                    source_id=row["source_id"],
                    disposition=self.IMPORT_DISPOSITIONS.get(text_id, text_id),
                )
                if row["article_id"]:
                    action["article"] = row["article_id"]
                if row["message"]:
                    action["message"] = row["message"]
                batch_id = row["import_batch_id"]
                if batch_id not in actions:
                    actions[batch_id] = []
                actions[batch_id].append(action)
        path = "../unversioned/exported/import_batches.json"
        with open(path, "w", encoding="utf-8") as fp:
            offset = 0
            batch_size = 5000
            while True:
                self.cursor.execute(
                    "SELECT * FROM ebms_import_batch ORDER BY import_batch_id "
                    f"LIMIT {offset}, {batch_size}"
                )
                offset += batch_size
                rows = self.cursor.fetchall()
                if not rows:
                    break
                for row in rows:
                    batch_id = row["import_batch_id"]
                    batch = dict(
                        id=batch_id,
                        topic=row["topic_id"],
                        source=row["source"],
                        imported=str(row["import_date"]),
                        cycle=self.cycles[row["cycle_id"]],
                        user=row["user_id"],
                        not_list=row.get("not_list")=="Y",
                        import_type=row["input_type"],
                        article_count=row["article_count"],
                        success=row.get("status")=="Success",
                    )
                    if batch_id in actions:
                        batch["actions"] = actions[batch_id]
                    if row["comment"]:
                        batch["comment"] = row["comment"]
                    if row["messages"]:
                        batch["messages"] = [row["messages"]]
                    fp.write(f"{dumps(batch)}\n")
        path = "../unversioned/exported/import_requests.json"
        with open(path, "w", encoding="utf-8") as fp:
            offset = 0
            batch_size = 2000
            while True:
                self.cursor.execute(
                    "SELECT * FROM ebms_import_request ORDER "
                    f"BY request_id LIMIT {offset}, {batch_size}"
                )
                offset += batch_size
                rows = self.cursor.fetchall()
                if not rows:
                    break
                for row in rows:
                    report_data = loads(row["report_data"])
                    batch_id = report_data.get("batchId")
                    if batch_id:
                        batch_id = int(batch_id)
                        messages = report_data.get("messages")
                        messages = [messages] if messages else []
                        status = report_data.get("status", "Success")
                        report = dict(
                            actions=actions.get(batch_id, []),
                            article_count=report_data["articleCount"],
                            batch=batch_id,
                            cycle=self.cycles[int(report_data["cycleId"])],
                            import_type=report_data["inputType"],
                            imported=report_data["dateTime"],
                            not_list=report_data["notList"]=="Y",
                            source=report_data["source"],
                            success=status=="Success",
                            user=int(report_data["userId"]),
                        )
                        if report_data.get("comment"):
                            report["comment"] = report_data["comment"]
                        if report_data.get("messages"):
                            report["messages"] = [report_data["messages"]]
                        if report_data.get("comment"):
                            report["comment"] = report_data["comment"]
                        if report_data.get("topicId"):
                            report["topic"]=int(report_data["topicId"])
                        request = dict(
                            id=row["request_id"],
                            params=row["request_params"],
                            report=dumps(report),
                        )
                        fp.write(f"{dumps(request)}\n")

    def journals(self):
        """Export JSON records for the journals cataloged by NLM."""

        self.__announce("journals")
        core = set()
        self.cursor.execute("SELECT * FROM ebms_core_journal");
        for row in self.cursor.fetchall():
            core.add(row["source_jrnl_id"])
        not_lists = {}
        self.cursor.execute("SELECT * FROM ebms_not_list ORDER BY board_id")
        for row in self.cursor.fetchall():
            journal_id = row["source_jrnl_id"]
            if journal_id not in not_lists:
                not_lists[journal_id] = []
            not_lists[journal_id].append(dict(
                board=row["board_id"],
                start=str(row["start_date"]),
                user=row["user_id"],
            ))
        self.cursor.execute("SELECT * FROM ebms_journal ORDER BY "
                            "brf_jrnl_title, source_jrnl_id")
        path = "../unversioned/exported/journals.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                journal_id = row["source_jrnl_id"]
                is_core_journal = journal_id in core
                journal = dict(
                    source=row["source"],
                    source_id=journal_id,
                    title=row["jrnl_title"],
                    brief_title=row["brf_jrnl_title"],
                    core=is_core_journal,
                    not_lists=not_lists.get(journal_id),
                )
                fp.write(f"{dumps(journal)}\n")

    def meetings(self):
        """Export JSON-encoded records for the EBMS meeting events."""

        self.__announce("meetings")
        agendas = {}
        self.cursor.execute("SELECT * FROM field_data_field_agenda")
        for row in self.cursor.fetchall():
            agendas[row["entity_id"]] = dict(
                value=self.__fix_links(row["field_agenda_value"]),
                format="filtered_html",
            )
        agenda_statuses = {}
        self.cursor.execute("SELECT * FROM field_data_field_agenda_status")
        for row in self.cursor.fetchall():
            status = row["field_agenda_status_value"]
            agenda_statuses[row["entity_id"]] = status
        boards = {}
        self.cursor.execute(
            "SELECT * FROM field_data_field_boards WHERE bundle = "
            "'ebms_event' ORDER BY field_boards_value"
        )
        for row in self.cursor.fetchall():
            meeting_id = row["entity_id"]
            if meeting_id not in boards:
                boards[meeting_id] = []
            boards[meeting_id].append(row["field_boards_value"])
        categories = {}
        self.cursor.execute("SELECT * FROM field_data_field_event_category")
        for row in self.cursor.fetchall():
            categories[row["entity_id"]] = row["field_event_category_value"]
        dates = {}
        self.cursor.execute("SELECT * FROM field_data_field_datespan")
        for row in self.cursor.fetchall():
            start = datetime.fromtimestamp(row["field_datespan_value"])
            end = datetime.fromtimestamp(row["field_datespan_value2"])
            dates[row["entity_id"]] = dict(
                value=start.strftime("%Y-%m-%dT%H:%M:%S"),
                end_value=end.strftime("%Y-%m-%dT%H:%M:%S"),
            )
        docs = {}
        self.cursor.execute(
            "SELECT * FROM field_data_field_documents "
            "ORDER BY field_documents_fid"
        )
        for row in self.cursor.fetchall():
            meeting_id = row["entity_id"]
            if meeting_id not in docs:
                docs[meeting_id] = []
            docs[meeting_id].append(row["field_documents_fid"])
        groups = {}
        for group_type in ("subgroups", "ad_hoc_groups"):
            column_name = f"field_{group_type}_value"
            self.cursor.execute(
                f"SELECT * FROM field_data_field_{group_type}"
                " WHERE bundle = 'ebms_event'"
                f" ORDER BY {column_name}"
            )
            for row in self.cursor.fetchall():
                meeting_id = row["entity_id"]
                if meeting_id not in groups:
                    groups[meeting_id] = {}
                if group_type not in groups[meeting_id]:
                    groups[meeting_id][group_type] = []
                groups[meeting_id][group_type].append(row[column_name])
        individuals = {}
        self.cursor.execute(
            "SELECT * FROM field_data_field_individuals"
            " WHERE bundle = 'ebms_event'"
            " ORDER BY field_individuals_value"
        )
        for row in self.cursor.fetchall():
            meeting_id = row["entity_id"]
            if meeting_id not in individuals:
                individuals[meeting_id] = []
            individuals[meeting_id].append(row["field_individuals_value"])
        notes = {}
        self.cursor.execute(
            "SELECT * FROM field_data_field_notes WHERE bundle = 'ebms_event'"
        )
        for row in self.cursor.fetchall():
            notes[row["entity_id"]] = dict(
                value=self.__fix_links(row["field_notes_value"]),
                format="filtered_html",
            )
        statuses = {}
        self.cursor.execute("SELECT * FROM field_data_field_event_status")
        for row in self.cursor.fetchall():
            statuses[row["entity_id"]] = row["field_event_status_value"]
        types = {}
        self.cursor.execute("SELECT * FROM field_data_field_event_type"
                            " WHERE bundle = 'ebms_event'")
        for row in self.cursor.fetchall():
            types[row["entity_id"]] = row["field_event_type_value"]
        meetings = []
        self.cursor.execute(
            "SELECT * FROM node WHERE type = 'ebms_event' ORDER BY nid"
        )
        path = "../unversioned/exported/meetings.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                nid = row["nid"]
                meeting = dict(
                    id=nid,
                    user=row["uid"],
                    entered=str(datetime.fromtimestamp(row["created"])),
                    name=row["title"],
                    dates=dates.get(nid),
                    type=types.get(nid),
                    category=categories.get(nid),
                    status=statuses.get(nid),
                    boards=boards.get(nid),
                    groups=groups.get(nid),
                    individuals=individuals.get(nid),
                    agenda=agendas.get(nid),
                    agenda_published=agenda_statuses.get(nid),
                    published=row["status"],
                    documents=docs.get(nid),
                    notes=notes.get(nid),
                )
                fp.write(f"{dumps(meeting)}\n")

    def messages(self):
        """Export information shown on the users' home pages."""

        self.__announce("messages")

        # Collect the message field values from related tables.
        self.cursor.execute(
            "SELECT table_name FROM information_schema.tables"
            " WHERE table_name LIKE 'field_data_field%'"
            " AND table_schema = 'oce_ebms'"
            " ORDER BY table_name"
        )
        field_tables = [row["table_name"] for row in self.cursor.fetchall()]
        message_values = {}
        for table in field_tables:
            self.cursor.execute(
                f"SELECT COUNT(*) n FROM {table} WHERE entity_type = 'message'"
            )
            if self.cursor.fetchone()["n"] < 1:
                continue
            field = table.replace("field_data_field_", "")
            column = f"field_{field}_value"
            self.cursor.execute(
                f"SELECT entity_id AS mid, {column} AS value FROM {table}"
                " WHERE entity_type = 'message'"
                " AND deleted = 0"
                " ORDER BY entity_id, delta"
            )
            for row in self.cursor.fetchall():
                mid = row["mid"]
                if mid not in message_values:
                    message_values[mid] = {}
                if field not in message_values[mid]:
                    message_values[mid][field] = []
                message_values[mid][field].append(row["value"])

        # Now assemble and export each message.
        self.cursor.execute("SELECT * FROM message ORDER BY mid")
        path = "../unversioned/exported/messages.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                mid = row["mid"]
                values = dict(
                    id=mid,
                    message_type=self.MESSAGE_TYPES[row["type"]],
                    user=row["uid"],
                    posted=str(datetime.fromtimestamp(row["timestamp"])),
                )
                extra_values = {}
                if mid in message_values:
                    for field in sorted(message_values[mid]):
                        if field in self.MESSAGE_FIELDS:
                            values[field] = message_values[mid][field]
                        else:
                            value = message_values[mid][field][0]
                            if field.startswith("event_"):
                                field = field.replace("event_", "meeting_")
                            if field == "meeting_type":
                                value = self.MEETING_TYPES[value]
                            if field == "summary_url":
                                if value.startswith("sites"):
                                    value = f"/{value}"
                                value = self.__fix_links(value)
                            extra_values[field] = value
                values["extra_values"] = dumps(extra_values)
                fp.write(f"{dumps(values)}\n")

    def packets(self):
        """Export JSON records for packets and reviews."""

        self.__announce("packets")
        reviewer_docs = {}
        self.cursor.execute("SELECT * FROM ebms_reviewer_doc ORDER BY doc_id")
        path = "../unversioned/exported/reviewer_docs.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                doc_id = row["doc_id"]
                packet_id = row["packet_id"]
                values = dict(
                    id=doc_id,
                    file=row["file_id"],
                    reviewer=row["reviewer_id"],
                    posted=str(row["when_posted"]),
                    dropped=row["drop_flag"],
                )
                if row["description"]:
                    values["description"] = row["description"]
                fp.write(f"{dumps(values)}\n")
                if packet_id not in reviewer_docs:
                    reviewer_docs[packet_id] = []
                reviewer_docs[packet_id].append(doc_id)
        summaries = {}
        self.cursor.execute(
            "SELECT * FROM ebms_packet_summary"
            " ORDER BY packet_id, doc_id"
        )
        for row in self.cursor.fetchall():
            packet_id = row["packet_id"]
            if packet_id not in summaries:
                summaries[packet_id] = []
            summaries[packet_id].append(row["doc_id"])
        reviewers = {}
        self.cursor.execute(
            "SELECT * FROM ebms_packet_reviewer"
            " ORDER BY packet_id, reviewer_id"
        )
        for row in self.cursor.fetchall():
            packet_id = row["packet_id"]
            if packet_id not in reviewers:
                reviewers[packet_id] = []
            reviewers[packet_id].append(row["reviewer_id"])
        dispositions = {}
        self.cursor.execute(
            "SELECT * FROM ebms_review_disposition"
            " ORDER BY review_id, value_id"
        )
        for row in self.cursor.fetchall():
            review_id = row["review_id"]
            if review_id not in dispositions:
                dispositions[review_id] = []
            dispositions[review_id].append(row["value_id"])
        reasons = {}
        self.cursor.execute(
            "SELECT * FROM ebms_review_rejection_reason"
            " ORDER BY review_id, value_id"
        )
        for row in self.cursor.fetchall():
            review_id = row["review_id"]
            if review_id not in reasons:
                reasons[review_id] = []
            reasons[review_id].append(row["value_id"])
        reviews = {}
        offset = 0
        batch_size = 3000
        path = "../unversioned/exported/reviews.json"
        with open(path, "w", encoding="utf-8") as fp:
            while True:
                self.cursor.execute(
                    "SELECT * FROM ebms_article_review"
                    " ORDER BY review_id"
                    f" LIMIT {offset}, {batch_size}"
                )
                offset += batch_size
                rows = self.cursor.fetchall()
                if not rows:
                    break
                for row in rows:
                    review_id = row["review_id"]
                    packet_id = row["packet_id"]
                    article_id = row["article_id"]
                    values = dict(
                        id=review_id,
                        reviewer=row["reviewer_id"],
                        posted=str(row["when_posted"]),
                    )
                    if row["comments"]:
                        values["comments"] = row["comments"]
                    if row["loe_info"]:
                        values["loe_info"] = row["loe_info"]
                    if review_id in dispositions:
                        values["dispositions"] = dispositions[review_id]
                    if review_id in reasons:
                        values["reasons"] = reasons[review_id]
                    fp.write(f"{dumps(values)}\n")
                    key = f"{packet_id} {article_id}"
                    if key not in reviews:
                        reviews[key] = []
                    reviews[key].append(review_id)

        # We must ensure that these entity IDs are stable across runs.
        packet_article_ids = {}
        next_id = 1
        path = Path("../unversioned/packet_article_ids")
        if path.exists():
            with path.open(encoding="utf-8") as fp:
                packet_article_ids = load(fp)
            if packet_article_ids:
                next_id = max(packet_article_ids.values()) + 1
        articles = {}
        path = "../unversioned/exported/packet_articles.json"
        with open(path, "w", encoding="utf-8") as fp:

            # Get these in one query to make sure new ones don't slip in.
            self.cursor.execute(
                "SELECT * FROM ebms_packet_article"
                " ORDER BY packet_id, article_id"
            )
            for row in self.cursor.fetchall():
                packet_id = row["packet_id"]
                article_id = row["article_id"]
                key = f"{packet_id} {article_id}"
                packet_article_id = packet_article_ids.get(key)
                if not packet_article_id:
                    packet_article_id = next_id
                    next_id += 1
                    packet_article_ids[key] = packet_article_id
                values = dict(
                    id=packet_article_id,
                    article=article_id,
                    dropped=row["drop_flag"],
                )
                if packet_id not in articles:
                    articles[packet_id] = []
                articles[packet_id].append(packet_article_id)
                if row["archived"]:
                    values["archived"] = str(row["archived"])
                if key in reviews:
                    values["reviews"] = reviews[key]
                fp.write(f"{dumps(values)}\n")

        # Remember the IDs assigned to packet/article combinations.
        path = "../unversioned/packet_article_ids"
        with open(path, "w", encoding="utf-8") as fp:
            dump(packet_article_ids, fp, indent=2)
        for key in reviews:
            if key not in packet_article_ids:
                packet_id, article_id = key.split()
                print(
                    f"article {article_id} not in packet {packet_id} "
                    "for which it was reviewed"
                )
        self.cursor.execute("SELECT * FROM ebms_packet ORDER BY packet_id")
        path = "../unversioned/exported/packets.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                packet_id = row["packet_id"]
                values = dict(
                    id=packet_id,
                    topic=row["topic_id"],
                    created_by=row["created_by"],
                    created=str(row["created_at"]),
                    title=row["packet_title"].strip(),
                    articles=articles[packet_id],
                    active=row["active_status"]=="A",
                    starred=row["starred"],
                )
                if row["last_seen"]:
                    values["last_seen"] = str(row["last_seen"])
                if packet_id in reviewers:
                    values["reviewers"] = reviewers[packet_id]
                if packet_id in summaries:
                    values["summaries"] = summaries[packet_id]
                if packet_id in reviewer_docs:
                    values["reviewer_docs"] = reviewer_docs[packet_id]
                fp.write(f"{dumps(values)}\n")

    def states(self):
        """Export JSON records for each of the article/topic states."""

        self.__announce("states")
        if self.opts.verbose:
            collected = 0
        comments = {}
        self.cursor.execute(
            "SELECT * FROM ebms_article_state_comment ORDER BY comment_id"
        )
        for row in self.cursor.fetchall():
            if row["comment"]:
                comment = dict(
                    user=row["user_id"],
                    entered=str(row["comment_dt"]),
                    body=row["comment"],
                )
                article_state_id = row["article_state_id"]
                if article_state_id not in comments:
                    comments[article_state_id] = []
                comments[article_state_id].append(comment)
                if self.opts.verbose:
                    collected += 1
        if self.opts.verbose:
            print(f"collected {collected} state comments")
            collected = 0
        decisions = {}
        self.cursor.execute(
            "SELECT * FROM ebms_article_board_decision"
            " ORDER BY article_state_id, decision_value_id"
        )
        for row in self.cursor.fetchall():
            values = dict(
                decision=row["decision_value_id"],
                discussed=row["discussed"]=="Y",
            )
            if row["meeting_date"]:
                values["meeting_date"] = self.cycles[row["meeting_date"]]
            article_state_id = row["article_state_id"]
            if article_state_id not in decisions:
                decisions[article_state_id] = []
            decisions[article_state_id].append(values)
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} state board decisions")
            collected = 0
        deciders = {}
        self.cursor.execute(
            "SELECT * FROM ebms_article_board_decision_member"
            " ORDER BY article_state_id, uid"
        )
        for row in self.cursor.fetchall():
            article_state_id = row["article_state_id"]
            if article_state_id not in deciders:
                deciders[article_state_id] = []
            deciders[article_state_id].append(row["uid"])
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} state board deciders")
            collected = 0
        meetings = {}
        self.cursor.execute(
            "SELECT * FROM ebms_agenda_meeting"
            " ORDER BY nid, article_state_id"
        )
        for row in self.cursor.fetchall():
            article_state_id = row["article_state_id"]
            if article_state_id not in meetings:
                meetings[article_state_id] = []
            meetings[article_state_id].append(row["nid"])
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} state meetings")
            done = 0
        offset = 0
        batch_size = 10000
        path = "../unversioned/exported/states.json"
        with open(path, "w", encoding="utf-8") as fp:
            while True:
                self.cursor.execute(
                    "SELECT * FROM ebms_article_state"
                    " ORDER BY article_state_id"
                    f" LIMIT {offset}, {batch_size}"
                )
                offset += batch_size
                rows = self.cursor.fetchall()
                if not rows:
                    break
                for row in rows:
                    article_state_id = row["article_state_id"]
                    state = dict(
                        id=article_state_id,
                        article=row["article_id"],
                        value=row["state_id"],
                        board=row["board_id"],
                        topic=row["topic_id"],
                        user=row["user_id"],
                        entered=str(row["status_dt"]),
                        active=row["active_status"]=="A",
                        current=row["current"]=="Y",
                    )
                    state["comments"] = comments.get(article_state_id)
                    if article_state_id in decisions:
                        state["decisions"] = decisions[article_state_id]
                    if article_state_id in deciders:
                        state["deciders"] = deciders[article_state_id]
                    if article_state_id in meetings:
                        state["meetings"] = meetings[article_state_id]
                    fp.write(f"{dumps(state)}\n")
                    if self.opts.verbose:
                        done += 1
                        print(f"\rexported {done} states", end="")
        if self.opts.verbose:
            print()

    def summaries(self):
        """Export JSON records for the summary pages."""

        self.__announce("summaries")
        topics = {}
        self.cursor.execute(
            "SELECT * FROM ebms_summary_page_topic"
            " ORDER BY topic_id"
        )
        for row in self.cursor.fetchall():
            page_id = row["page_id"]
            if page_id not in topics:
                topics[page_id] = []
            topics[page_id].append(row["topic_id"])
        links = {}
        self.cursor.execute("SELECT * FROM ebms_summary_link ORDER BY link_id")
        for row in self.cursor.fetchall():
            page_id = row["page_id"]
            if page_id not in links:
                links[page_id] = []
            links[page_id].append(dict(
                uri=row["link_url"],
                title=row["link_label"],
            ))
        manager_docs = {}
        self.cursor.execute(
            "SELECT * FROM ebms_summary_posted_doc"
            " ORDER BY page_id, doc_id"
        )
        for row in self.cursor.fetchall():
            page_id = row["page_id"]
            if page_id not in manager_docs:
                manager_docs[page_id] = []
            manager_docs[page_id].append(dict(
                doc=row["doc_id"],
                notes=row["notes"] or None,
                active=not row["archived"],
            ))
        member_docs = {}
        self.cursor.execute(
            "SELECT * FROM ebms_summary_returned_doc"
            " ORDER BY page_id, doc_id"
        )
        for row in self.cursor.fetchall():
            page_id = row["page_id"]
            if page_id not in member_docs:
                member_docs[page_id] = []
            member_docs[page_id].append(dict(
                doc=row["doc_id"],
                notes=row["notes"] or None,
                active=not row["archived"],
            ))
        boards = {}
        self.cursor.execute("SELECT board_id FROM ebms_board ORDER BY 1")
        for row in self.cursor.fetchall():
            board_id = row["board_id"]
            boards[board_id] = dict(
                board=board_id,
                pages=[],
                docs=[],
            )
        self.cursor.execute(
            "SELECT * FROM ebms_summary_supporting_doc"
            " ORDER BY board_id, doc_id"
        )
        for row in self.cursor.fetchall():
            board_id = row["board_id"]
            boards[row["board_id"]]["docs"].append(dict(
                doc=row["doc_id"],
                notes=row["notes"] or None,
                active=not row["archived"],
            ))
        pages = []
        self.cursor.execute("SELECT * FROM ebms_summary_page ORDER BY page_id")
        path = "../unversioned/exported/summary_pages.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                page_id = row["page_id"]
                board_id = row["board_id"]
                boards[board_id]["pages"].append(page_id)
                page = dict(
                    id=page_id,
                    name=row["page_name"],
                    topics=topics.get(page_id),
                    links=links.get(page_id),
                    manager_docs=manager_docs.get(page_id),
                    member_docs=member_docs.get(page_id),
                    active=not row["archived"],
                )
                fp.write(f"{dumps(page)}\n")
        path = "../unversioned/exported/board_summaries.json"
        with open(path, "w", encoding="utf-8") as fp:
            for board_id in sorted(boards):
                fp.write(f"{dumps(boards[board_id])}\n")

    def tags(self):
        """Export JSON records for the tags assigned to EBMS articles."""

        self.__announce("article tags")
        comments = {}
        self.cursor.execute(
            "SELECT * FROM ebms_article_tag_comment ORDER BY comment_id"
        )
        for row in self.cursor.fetchall():
            article_tag_id = row["article_tag_id"]
            comment = dict(
                user=row["user_id"],
                entered=str(row["comment_dt"]),
                body=row["comment"],
            )
            if article_tag_id not in comments:
                comments[article_tag_id] = []
            comments[article_tag_id].append(comment)
        self.cursor.execute(
            "SELECT * FROM ebms_article_tag ORDER BY article_tag_id"
        )
        path = "../unversioned/exported/article_tags.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                article_tag_id = row["article_tag_id"]
                tag = dict(
                    id=article_tag_id,
                    tag=row["tag_id"],
                    user=row["user_id"],
                    assigned=str(row["tag_dt"]),
                    active=row["active_status"]=="A",
                )
                if article_tag_id in comments:
                    tag["comments"] = comments[article_tag_id]
                fp.write(f"{dumps(tag)}\n")

    def topics(self):
        """Export JSON records for the EBMS review topics."""

        self.__announce("topics")
        self.cursor.execute("SELECT * FROM ebms_topic ORDER BY topic_id")
        topics = []
        path = "../unversioned/exported/topics.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                topic = dict(
                    id=row["topic_id"],
                    name=row["topic_name"],
                    board=row["board_id"],
                    nci_reviewer=row["nci_reviewer"],
                    topic_group=row["topic_group"],
                    active=row["active_status"]=="A",
                )
                fp.write(f"{dumps(topic)}\n")

    def travel(self):
        """Export travel information (hotel and reimbursement requests)."""

        self.__announce("travel requests")
        request_values = {}
        self.cursor.execute(
            "SELECT d.sid, d.data, c.form_key"
            "  FROM webform_submitted_data d"
            "  JOIN webform_component c"
            "    ON c.cid = d.cid"
            "   AND c.nid = d.nid"
           f" WHERE d.nid = {self.HOTEL_REQUEST_FORM_NODE_ID}"
        )
        for row in self.cursor.fetchall():
            value = row["data"]
            if value:
                sid = row["sid"]
                field = row["form_key"]
                if field == "meeting":
                    value = int(value)
                if sid not in request_values:
                    request_values[sid] = {}
                request_values[sid][field] = value
        self.cursor.execute(
            "SELECT * FROM webform_submissions"
            f" WHERE nid = {self.HOTEL_REQUEST_FORM_NODE_ID}"
            " ORDER BY sid"
        )
        path = "../unversioned/exported/hotel_requests.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                sid = row["sid"]
                values = dict(
                    id=sid,
                    user=row["uid"],
                    submitted=str(datetime.fromtimestamp(row["submitted"])),
                    remote_address=row["remote_addr"],
                )
                if sid in request_values:
                    for field in sorted(request_values[sid]):
                        values[field] = request_values[sid][field]
                fp.write(f"{dumps(values)}\n")
        request_values = {}
        self.cursor.execute(
            "SELECT d.sid, d.data, c.form_key"
            "  FROM webform_submitted_data d"
            "  JOIN webform_component c"
            "    ON c.cid = d.cid"
            "   AND c.nid = d.nid"
           f" WHERE d.nid = {self.REIMBURSEMENT_REQUEST_FORM_NODE_ID}"
        )
        for row in self.cursor.fetchall():
            value = row["data"]
            if value:
                sid = row["sid"]
                field = row["form_key"]
                if field == "meeting":
                    value = int(value)
                if sid not in request_values:
                    request_values[sid] = {}
                request_values[sid][field] = value
        request_values_json = dumps(request_values).encode("utf-8")
        opts = dict(stdout=PIPE, stdin=PIPE, stderr=PIPE)
        script = "../unversioned/fix-reimbursement-values.php"
        process = Popen(["php", script], **opts)
        request_values_json = process.communicate(input=request_values_json)[0]
        request_values = loads(request_values_json)
        self.cursor.execute(
            "SELECT * FROM webform_submissions"
            f" WHERE nid = {self.REIMBURSEMENT_REQUEST_FORM_NODE_ID}"
            " ORDER BY sid"
        )
        path = "../unversioned/exported/reimbursement_requests.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                sid = row["sid"]
                values = dict(
                    id=sid,
                    user=row["uid"],
                    submitted=str(datetime.fromtimestamp(row["submitted"])),
                    remote_address=row["remote_addr"],
                )
                key = str(sid)
                if key in request_values:
                    for field in sorted(request_values[key]):
                        values[field] = request_values[key][field]
                fp.write(f"{dumps(values)}\n")

    def users(self):
        """Export JSON records for the EBMS user accounts."""

        self.__announce("users")
        defaults = {}
        for field, table in self.USER_DEFAULT_TABLES.items():
            value_map = self.USER_DEFAULT_MAP
            if table == "field_data_dft_cite_review_sort_key":
                value_map = self.REVIEW_SORT_MAP
            self.cursor.execute(f"SELECT * FROM {table}")
            defaults[field] = {}
            column_name = table[len("field_data_"):] + "_value"
            for row in self.cursor.fetchall():
                if row["entity_type"] == "user" and not row["deleted"]:
                    uid = row["entity_id"]
                    val = row[column_name]
                    defaults[field][uid] = value_map.get(val, val)
        topics = {}
        self.cursor.execute(
            "SELECT * FROM ebms_topic_reviewer ORDER BY topic_id, user_id"
        )
        for row in self.cursor.fetchall():
            uid = row["user_id"]
            if uid not in topics:
                topics[uid] = []
            topics[uid].append(row["topic_id"])
        roles = {}
        self.cursor.execute("SELECT * FROM users_roles ORDER BY uid, rid")
        for row in self.cursor.fetchall():
            uid = row["uid"]
            if uid not in roles:
                roles[uid] = []
            roles[uid].append(self.ROLE_MAP[row["rid"]])
        boards = {}
        self.cursor.execute(
            "SELECT * FROM ebms_board_member ORDER BY user_id, board_id"
        )
        for row in self.cursor.fetchall():
            uid = row["user_id"]
            if uid not in boards:
                boards[uid] = []
            boards[uid].append(row["board_id"])
        subgroups = {}
        self.cursor.execute(
            "SELECT * FROM ebms_subgroup_member ORDER BY user_id, sg_id"
        )
        for row in self.cursor.fetchall():
            uid = row["user_id"]
            if uid not in subgroups:
                subgroups[uid] = []
            subgroups[uid].append(row["sg_id"])
        ad_hoc_groups = {}
        self.cursor.execute(
            "SELECT * FROM ebms_ad_hoc_group_member"
            " ORDER BY user_id, group_id"
        )
        for row in self.cursor.fetchall():
            uid = row["user_id"]
            if uid not in ad_hoc_groups:
                ad_hoc_groups[uid] = []
            ad_hoc_groups[uid].append(row["group_id"])
        self.cursor.execute("SELECT * FROM users ORDER BY uid")
        path = "../unversioned/exported/users.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                uid = row["uid"]
                if uid > 1:
                    user = dict(
                        uid=uid,
                        name=row["name"],
                        created=row["created"],
                        access=row["access"],
                        login=row["login"],
                        status=row["status"],
                        roles=roles.get(uid),
                        boards=boards.get(uid),
                        subgroups=subgroups.get(uid),
                        ad_hoc_groups=ad_hoc_groups.get(uid),
                        topics=topics.get(uid),
                    )
                    if row["picture"]:
                        user["user_picture"] = row["picture"]
                    for field in defaults:
                        user[field] = defaults[field].get(uid)
                    fp.write(f"{dumps(user)}\n")
        self.cursor.execute(
            "SELECT uid, authname"
            "  FROM authmap"
            " WHERE module = 'nci_SSO_authentication'"
            " ORDER BY uid"
        )
        path = "../unversioned/exported/authmap.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    uid=row["uid"],
                    provider="ebms_core",
                    authname=row["authname"],
                )
                fp.write(f"{dumps(values)}\n")

    def vocabularies(self):
        """Export the vocabulary term sets used by the system."""

        self.__article_tag_vocabulary()
        self.__board_decision_vocabulary()
        self.__doc_tag_vocabulary()
        self.__import_disposition_vocabulary()
        self.__internal_tag_vocabulary()
        self.__print_job_status_vocabulary()
        self.__print_job_type_vocabulary()
        self.__rejection_reason_vocabulary()
        self.__relationship_type_vocabulary()
        self.__review_disposition_vocabulary()
        self.__state_vocabulary()
        self.__topic_group_vocabulary()

    def __article_tag_vocabulary(self):
        """Export JSON for the article tag vocabulary terms."""

        self.__announce("article tag vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_article_tag_type ORDER BY tag_id"
        )
        path = "../unversioned/exported/article_tags_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="article_tags",
                    id=row["tag_id"],
                    field_text_id=row["text_id"],
                    name=row["tag_name"],
                    description=row["description"],
                    field_topic_required=row["topic_required"]=="Y",
                    field_topic_allowed=row["text_id"]!="preliminary",
                    status=row["active_status"]=="A",
                )
                fp.write(f"{dumps(values)}\n")

    def __board_decision_vocabulary(self):
        """Export JSON for the board decision vocabulary terms."""

        self.__announce("board decision vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_article_board_decision_value ORDER BY value_id"
        )
        path = "../unversioned/exported/board_decisions_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="board_decisions",
                    id=row["value_id"],
                    name=row["value_name"],
                    status=True,
                )
                fp.write(f"{dumps(values)}\n")

    def __doc_tag_vocabulary(self):
        """Export JSON for the document tag vocabulary terms."""

        self.__announce("document tag vocabulary")
        self.cursor.execute("SELECT * FROM ebms_tag ORDER BY tag_id")
        path = "../unversioned/exported/doc_tags_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                description = row["tag_comment"].replace("theSum", "the Sum"),
                values = dict(
                    vid="doc_tags",
                    id=row["tag_id"],
                    field_text_id=row["tag_name"],
                    name=row["tag_name"].title(),
                    description=description,
                    status=True,
                )
                fp.write(f"{dumps(values)}\n")

    def __import_disposition_vocabulary(self):
        """Export JSON for the import disposition vocabulary terms."""

        self.__announce("import disposition vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_import_disposition ORDER BY disposition_id"
        )
        path = "../unversioned/exported/import_dispositions_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                characters = []
                for character in row["text_id"]:
                    if character.isupper():
                        characters.append("_")
                        character = character.lower()
                    characters.append(character)
                machine_name = "".join(characters)
                values = dict(
                    vid="import_dispositions",
                    id=row["disposition_id"],
                    field_text_id=machine_name,
                    name=row["disposition_name"].title(),
                    description=row["description"].replace("  ", " "),
                    status=row["active_status"]=="A",
                )
                fp.write(f"{dumps(values)}\n")

    def __internal_tag_vocabulary(self):
        """Export JSON for the internal tag vocabulary."""

        self.__announce("internal tag vocabulary")
        self.cursor.execute("SELECT * FROM ebms_internal_tag ORDER BY tag_id")
        path = "../unversioned/exported/internal_tags_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="internal_tags",
                    id=row["tag_id"],
                    name=row["tag_name"].strip(),
                    status=row["active_status"]=="A",
                )
                fp.write(f"{dumps(values)}\n")

    def __print_job_status_vocabulary(self):
        """Export JSON for the print job status vocabulary."""

        self.__announce("print job status vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_print_status_type ORDER BY print_job_status_id"
        )
        path = "../unversioned/exported/print_job_statuses_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="print_job_statuses",
                    name=row["print_job_status_id"].strip(),
                    description=row["description"],
                    status=True,
                )
                fp.write(f"{dumps(values)}\n")

    def __print_job_type_vocabulary(self):
        """Export JSON for the print job type vocabulary."""

        self.__announce("print job type vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_print_job_type ORDER BY print_job_type_id"
        )
        path = "../unversioned/exported/print_job_types_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="print_job_types",
                    name=row["print_job_type_id"].strip(),
                    description=row["description"],
                    status=True,
                )
                fp.write(f"{dumps(values)}\n")

    def __rejection_reason_vocabulary(self):
        """Export JSON for the article rejection reasons vocabulary."""

        self.__announce("rejection reason vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_review_rejection_value"
            " ORDER BY value_pos, value_id"
        )
        path = "../unversioned/exported/rejection_reasons_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="rejection_reasons",
                    id=row["value_id"],
                    name=row["value_name"],
                    description=row["extra_info"],
                    status=row["active_status"]=="A",
                    weight=row["value_pos"],
                )
                fp.write(f"{dumps(values)}\n")

    def __relationship_type_vocabulary(self):
        """Export JSON for the article relationship types."""

        self.__announce("relationship type vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_article_relation_type ORDER BY type_id"
        )
        path = "../unversioned/exported/relationship_types_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="relationship_types",
                    id=row["type_id"],
                    name=row["type_name"],
                    description=row["type_desc"],
                    status=row["active_status"]=="A",
                )
                fp.write(f"{dumps(values)}\n")

    def __review_disposition_vocabulary(self):
        """Export JSON for the article disposition vocabulary."""

        self.__announce("review disposition vocabulary")
        self.cursor.execute(
            "SELECT * FROM ebms_review_disposition_value ORDER BY value_id"
        )
        path = "../unversioned/exported/review_dispositions_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="dispositions",
                    id=row["value_id"],
                    name=row["value_name"],
                    description=row["instructions"],
                    weight=row["value_pos"],
                    status=True,
                )
                fp.write(f"{dumps(values)}\n")

    def __state_vocabulary(self):
        """Export JSON for the article state terms."""

        self.__announce("state vocabulary")
        self.cursor.execute("SELECT * FROM ebms_article_state_type")
        rows = {}
        for row in self.cursor.fetchall():
            rows[row["state_text_id"]] = row
        path = "../unversioned/exported/states_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for old_text_id, new_text_id in self.STATE_MACHINE_NAMES.items():
                row = rows[old_text_id]
                values = dict(
                    vid="states",
                    id=row["state_id"],
                    field_text_id=new_text_id,
                    name=row["state_name"],
                    description=row["description"],
                    field_terminal=row["completed"]=="Y",
                    field_sequence=row["sequence"],
                    weight=row["sequence"],
                    status=row["active_status"]=="A",
                )
                fp.write(f"{dumps(values)}\n")

    def __topic_group_vocabulary(self):
        """Export JSON for the topic group vocabulary."""

        self.__announce("topic group vocabulary")
        self.cursor.execute("SELECT * FROM ebms_topic_group ORDER BY group_id")
        path = "../unversioned/exported/topic_groups_vocabulary.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                values = dict(
                    vid="topic_groups",
                    id=row["group_id"],
                    name=row["group_name"],
                    status=row["active_status"]=="A",
                )
                fp.write(f"{dumps(values)}\n")

    def __article_topics(self):
        """Export JSON records for the topics assigned to the EBMS articles."""

        self.__announce("article topics")
        if self.opts.verbose:
            collected = 0
        comments = {}
        self.cursor.execute(
            "SELECT * FROM ebms_article_topic_comment ORDER BY comment_id"
        )
        for row in self.cursor.fetchall():
            comment = dict(
                user=row["created_by"],
                entered=str(row["created"]),
                comment=row["comment"],
            )
            if row["modified"]:
                comment["modified"] = str(row["modified"])
                comment["modified_by"] = row["modified_by"]
            article_id = row["article_id"]
            topic_id = row["topic_id"]
            key = f"{article_id}_{topic_id}"
            if key not in comments:
                comments[key] = []
            comments[key].append(comment)
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} article topic comments")
            collected = 0
        tags = {}
        self.cursor.execute(
            "SELECT * FROM ebms_article_tag"
            " WHERE topic_id IS NOT NULL"
            " ORDER BY article_tag_id"
        )
        for row in self.cursor.fetchall():
            article_id = row["article_id"]
            topic_id = row["topic_id"]
            key = f"{article_id}_{topic_id}"
            if key not in tags:
                tags[key] = []
            tags[key].append(row["article_tag_id"])
            if self.opts.verbose:
                collected += 1
        if self.opts.verbose:
            print(f"collected {collected} article topic tags")
            collected = 0
        states = {}
        self.cursor.execute(
            "SELECT article_state_id, article_id, topic_id"
            " FROM ebms_article_state"
            " ORDER BY article_state_id")
        rows = self.cursor.fetchall()
        for row in rows:
            article_id = row["article_id"]
            topic_id = row["topic_id"]
            key = f"{article_id}_{topic_id}"
            if key not in states:
                states[key] = []
            states[key].append(row["article_state_id"])
            if self.opts.verbose:
                collected += 1
                progress = f"\rcollected {collected} article topic states"
                print(progress, end="")
        article_topics = {}
        entities = []
        entity_id = 1
        if self.opts.verbose:
            print()
        self.cursor.execute(
            "SELECT * FROM ebms_article_topic ORDER BY article_state_id"
        )
        rows = self.cursor.fetchall()
        path = "../unversioned/exported/article_topics.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in rows:
                article_id = row["article_id"]
                topic_id = row["topic_id"]
                key = f"{article_id}_{topic_id}"
                values = dict(
                    id=entity_id,
                    topic=topic_id,
                    cycle=self.cycles[row["cycle_id"]],
                )
                if key in states:
                    values["states"] = states[key]
                if key in tags:
                    values["tags"] = tags[key]
                if key in comments:
                    values["comments"] = comments[key]
                entities.append(values)
                if article_id not in article_topics:
                    article_topics[article_id] = []
                article_topics[article_id].append(entity_id)
                if self.opts.verbose:
                    print(f"\rexported {entity_id} of {len(rows)} "
                          "article topics", end="")
                fp.write(f"{dumps(values)}\n")
                entity_id += 1
        if self.opts.verbose:
            print()
        return article_topics

    def __article_relationships(self):
        """Export JSON for the links between related EBMS articles."""

        self.__announce("article relationships")
        self.cursor.execute("SELECT * FROM ebms_related_article"
                            " ORDER BY relationship_id")
        path = "../unversioned/exported/article_relationships.json"
        with open(path, "w", encoding="utf-8") as fp:
            for row in self.cursor.fetchall():
                relationship = dict(
                    id=row["relationship_id"],
                    related=row["to_id"],
                    related_to=row["from_id"],
                    type=row["type_id"],
                    recorded=str(row["created"]),
                    recorded_by=row["created_by"],
                    suppress=False,
                )
                if row["inactivated"]:
                    relationship["inactvated"] = str(row["inactivated"])
                if row["inactivated_by"]:
                    relationship["inactivated_by"] = row["inactivated_by"]
                if row["comment"]:
                    relationship["comment"] = row["comment"]
                fp.write(f"{dumps(relationship)}\n")

    def __fix_links(self, body):
        """Account for the fact that the files directory has moved.

        Pass:
          body - html block to be adjusted as necessary

        Return:
          html block with links possibly adjusted
        """

        if not body or self.OLD_FILES_LOCATION not in body:
            return body
        body = body.replace(self.OLD_ABSOLUTE, f"/{self.NEW_FILES_LOCATION}")
        return body.replace(self.OLD_FILES_LOCATION, self.NEW_FILES_LOCATION)

    def __announce(self, exporting):
        """Show what we're about to export.

        Pass:
          exporting - string identifying what we're exporting
        """

        stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{stamp}] exporting {exporting}")


if __name__ == "__main__":
    Exporter().run()
